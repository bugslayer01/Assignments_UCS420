{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c2ede3-313f-4488-8065-553006a1efa6",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "### Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports, technology, food, books, etc.).\n",
    "1. Convert text to lowercase and remove punctuaƟon.\n",
    "2. Tokenize the text into words and sentences.\n",
    "3. Remove stopwords (using NLTK's stopwords list).\n",
    "4. Display word frequency distribuƟon (excluding stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe0056b-d290-4f14-bb39-9684e86fdda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\parth\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\parth\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\parth\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\parth\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\parth\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab118907-6830-4a80-b3b5-db101ec4f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"\n",
    "Trees are vital to life on Earth. They provide us with oxygen, improve air quality, conserve water, and support countless ecosystems. Trees offer shade, reduce the effects of climate change by absorbing carbon dioxide, and prevent soil erosion with their strong roots. They also provide food, shelter, and protection for many species of animals. In urban areas, trees enhance beauty, lower temperatures, and promote well-being among people. Forests, made up of trees, are often called the lungs of our planet. Without trees, life as we know it would not be possible. Protecting and planting trees is crucial for our future.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3cd1155-77b3-41d6-902e-b4513ec1950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trees are vital to life on earth they provide us with oxygen improve air quality conserve water and support countless ecosystems trees offer shade reduce the effects of climate change by absorbing carbon dioxide and prevent soil erosion with their strong roots they also provide food shelter and protection for many species of animals in urban areas trees enhance beauty lower temperatures and promote wellbeing among people forests made up of trees are often called the lungs of our planet without trees life as we know it would not be possible protecting and planting trees is crucial for our future\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "text_low = sentence.lower()\n",
    "no_punc = text_low.translate(str.maketrans('', '', string.punctuation))\n",
    "print(no_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e71e258-fca7-45b3-8601-f8a994fc4ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\parth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2519cfc0-eacc-430e-bff6-12762151e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words:   ['trees', 'are', 'vital', 'to', 'life', 'on', 'earth', 'they', 'provide', 'us', 'with', 'oxygen', 'improve', 'air', 'quality', 'conserve', 'water', 'and', 'support', 'countless', 'ecosystems', 'trees', 'offer', 'shade', 'reduce', 'the', 'effects', 'of', 'climate', 'change', 'by', 'absorbing', 'carbon', 'dioxide', 'and', 'prevent', 'soil', 'erosion', 'with', 'their', 'strong', 'roots', 'they', 'also', 'provide', 'food', 'shelter', 'and', 'protection', 'for', 'many', 'species', 'of', 'animals', 'in', 'urban', 'areas', 'trees', 'enhance', 'beauty', 'lower', 'temperatures', 'and', 'promote', 'wellbeing', 'among', 'people', 'forests', 'made', 'up', 'of', 'trees', 'are', 'often', 'called', 'the', 'lungs', 'of', 'our', 'planet', 'without', 'trees', 'life', 'as', 'we', 'know', 'it', 'would', 'not', 'be', 'possible', 'protecting', 'and', 'planting', 'trees', 'is', 'crucial', 'for', 'our', 'future'] \n",
      "\n",
      "Tokenized Sentences:   ['\\nTrees are vital to life on Earth.', 'They provide us with oxygen, improve air quality, conserve water, and support countless ecosystems.', 'Trees offer shade, reduce the effects of climate change by absorbing carbon dioxide, and prevent soil erosion with their strong roots.', 'They also provide food, shelter, and protection for many species of animals.', 'In urban areas, trees enhance beauty, lower temperatures, and promote well-being among people.', 'Forests, made up of trees, are often called the lungs of our planet.', 'Without trees, life as we know it would not be possible.', 'Protecting and planting trees is crucial for our future.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(no_punc)\n",
    "sent = sent_tokenize(sentence)\n",
    "print(\"Tokenized words:  \", words,\"\\n\")\n",
    "print(\"Tokenized Sentences:  \", sent,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b03bed-d826-4e1b-8b09-6bc742c95667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\parth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopper = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16f21f29-e0f5-425b-ad6b-97feb0757d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Word Tokens:\n",
      " ['trees', 'vital', 'life', 'earth', 'provide', 'us', 'oxygen', 'improve', 'air', 'quality', 'conserve', 'water', 'support', 'countless', 'ecosystems', 'trees', 'offer', 'shade', 'reduce', 'effects', 'climate', 'change', 'absorbing', 'carbon', 'dioxide', 'prevent', 'soil', 'erosion', 'strong', 'roots', 'also', 'provide', 'food', 'shelter', 'protection', 'many', 'species', 'animals', 'urban', 'areas', 'trees', 'enhance', 'beauty', 'lower', 'temperatures', 'promote', 'wellbeing', 'among', 'people', 'forests', 'made', 'trees', 'often', 'called', 'lungs', 'planet', 'without', 'trees', 'life', 'know', 'would', 'possible', 'protecting', 'planting', 'trees', 'crucial', 'future'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopper_removed = [w for w in words if w not in stopper]\n",
    "print(\"Filtered Word Tokens:\\n\", stopper_removed ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04b7aa6f-0141-43ef-8c21-ac3fe7a8e75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Frequency Distribution:\n",
      "trees: 6\n",
      "vital: 1\n",
      "life: 2\n",
      "earth: 1\n",
      "provide: 2\n",
      "us: 1\n",
      "oxygen: 1\n",
      "improve: 1\n",
      "air: 1\n",
      "quality: 1\n",
      "conserve: 1\n",
      "water: 1\n",
      "support: 1\n",
      "countless: 1\n",
      "ecosystems: 1\n",
      "offer: 1\n",
      "shade: 1\n",
      "reduce: 1\n",
      "effects: 1\n",
      "climate: 1\n",
      "change: 1\n",
      "absorbing: 1\n",
      "carbon: 1\n",
      "dioxide: 1\n",
      "prevent: 1\n",
      "soil: 1\n",
      "erosion: 1\n",
      "strong: 1\n",
      "roots: 1\n",
      "also: 1\n",
      "food: 1\n",
      "shelter: 1\n",
      "protection: 1\n",
      "many: 1\n",
      "species: 1\n",
      "animals: 1\n",
      "urban: 1\n",
      "areas: 1\n",
      "enhance: 1\n",
      "beauty: 1\n",
      "lower: 1\n",
      "temperatures: 1\n",
      "promote: 1\n",
      "wellbeing: 1\n",
      "among: 1\n",
      "people: 1\n",
      "forests: 1\n",
      "made: 1\n",
      "often: 1\n",
      "called: 1\n",
      "lungs: 1\n",
      "planet: 1\n",
      "without: 1\n",
      "know: 1\n",
      "would: 1\n",
      "possible: 1\n",
      "protecting: 1\n",
      "planting: 1\n",
      "crucial: 1\n",
      "future: 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "frequency_dist = FreqDist(stopper_removed)\n",
    "print(\"\\nWord Frequency Distribution:\")\n",
    "for word, frequency in frequency_dist.items():\n",
    "    print(f\"{word}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910039f1-ab9c-4a29-8c5a-8c3f1a488b4c",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "### Stemming and Lemmatization\n",
    "1. Take the tokenized words from QuesƟon 1 (aŌer stopword removal).\n",
    "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
    "3. Apply lemmaƟzaƟon using NLTK's WordNetLemmaƟzer.\n",
    "4. Compare and display results of both techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d73d1f7d-bb88-40a6-9eda-13bd1452b3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\parth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\parth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') \n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "portered = [porter.stem(w) for w in stopper_removed]\n",
    "lancastered = [lancaster.stem(w) for w in stopper_removed]\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in stopper_removed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dcdf1ec-56fc-496e-8efc-491dd2089bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original            Porter              Lancaster           Lemma              \n",
      "------------------------------------------------------------\n",
      "trees               tree                tre                 tree               \n",
      "vital               vital               vit                 vital              \n",
      "life                life                lif                 life               \n",
      "earth               earth               ear                 earth              \n",
      "provide             provid              provid              provide            \n",
      "us                  us                  us                  u                  \n",
      "oxygen              oxygen              oxyg                oxygen             \n",
      "improve             improv              improv              improve            \n",
      "air                 air                 air                 air                \n",
      "quality             qualiti             qual                quality            \n",
      "conserve            conserv             conserv             conserve           \n",
      "water               water               wat                 water              \n",
      "support             support             support             support            \n",
      "countless           countless           countless           countless          \n",
      "ecosystems          ecosystem           ecosystem           ecosystem          \n",
      "trees               tree                tre                 tree               \n",
      "offer               offer               off                 offer              \n",
      "shade               shade               shad                shade              \n",
      "reduce              reduc               reduc               reduce             \n",
      "effects             effect              effect              effect             \n",
      "climate             climat              clim                climate            \n",
      "change              chang               chang               change             \n",
      "absorbing           absorb              absorb              absorbing          \n",
      "carbon              carbon              carbon              carbon             \n",
      "dioxide             dioxid              dioxid              dioxide            \n",
      "prevent             prevent             prev                prevent            \n",
      "soil                soil                soil                soil               \n",
      "erosion             eros                erod                erosion            \n",
      "strong              strong              strong              strong             \n",
      "roots               root                root                root               \n",
      "also                also                also                also               \n",
      "provide             provid              provid              provide            \n",
      "food                food                food                food               \n",
      "shelter             shelter             shelt               shelter            \n",
      "protection          protect             protect             protection         \n",
      "many                mani                many                many               \n",
      "species             speci               specy               specie             \n",
      "animals             anim                anim                animal             \n",
      "urban               urban               urb                 urban              \n",
      "areas               area                area                area               \n",
      "trees               tree                tre                 tree               \n",
      "enhance             enhanc              enh                 enhance            \n",
      "beauty              beauti              beauty              beauty             \n",
      "lower               lower               low                 lower              \n",
      "temperatures        temperatur          temp                temperature        \n",
      "promote             promot              promot              promote            \n",
      "wellbeing           wellb               wellb               wellbeing          \n",
      "among               among               among               among              \n",
      "people              peopl               peopl               people             \n",
      "forests             forest              forest              forest             \n",
      "made                made                mad                 made               \n",
      "trees               tree                tre                 tree               \n",
      "often               often               oft                 often              \n",
      "called              call                cal                 called             \n",
      "lungs               lung                lung                lung               \n",
      "planet              planet              planet              planet             \n",
      "without             without             without             without            \n",
      "trees               tree                tre                 tree               \n",
      "life                life                lif                 life               \n",
      "know                know                know                know               \n",
      "would               would               would               would              \n",
      "possible            possibl             poss                possible           \n",
      "protecting          protect             protect             protecting         \n",
      "planting            plant               plant               planting           \n",
      "trees               tree                tre                 tree               \n",
      "crucial             crucial             cruc                crucial            \n",
      "future              futur               fut                 future             \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Original':<19} {'Porter':<19} {'Lancaster':<19} {'Lemma':<19}\")\n",
    "print(\"-\" * 60)\n",
    "for o, p, l, le in zip(stopper_removed, portered, lancastered, lemmatized):\n",
    "    print(\"{:<19} {:<19} {:<19} {:<19}\".format(o, p, l, le))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f3f33a-5e64-4d4b-8ae4-6ce4e8665250",
   "metadata": {},
   "source": [
    "# Question 3. Regular Expressions and Text Spliƫng\n",
    "1. Take their original text from Question 1.\n",
    "2. Use regular expressions to:\n",
    " \n",
    "    - a. Extract all words with more than 5 letters.\n",
    " \n",
    "    - b. Extract all numbers (if any exist in their text).\n",
    " \n",
    "    - c. Extract all capitalized words.\n",
    "3. Use text spliƫng techniques to:\n",
    "   \n",
    "    - a. Split the text into words containing only alphabets (removing digits and specialcharacters).\n",
    "    - b. Extract words starting with a vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c9b492d-7dfb-492d-9182-135ac4aedc5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words (>5) letters:   ['provide', 'oxygen', 'improve', 'quality', 'conserve', 'support', 'countless', 'ecosystems', 'reduce', 'effects', 'climate', 'change', 'absorbing', 'carbon', 'dioxide', 'prevent', 'erosion', 'strong', 'provide', 'shelter', 'protection', 'species', 'animals', 'enhance', 'beauty', 'temperatures', 'promote', 'wellbeing', 'people', 'forests', 'called', 'planet', 'without', 'possible', 'protecting', 'planting', 'crucial', 'future'] \n",
      "\n",
      "\n",
      "Numbers :   [] \n",
      "\n",
      "\n",
      "Capitalized :   ['Trees', 'Earth', 'They', 'Trees', 'They', 'In', 'Forests', 'Without', 'Protecting'] \n",
      "\n",
      "\n",
      "Only alpha words:   ['trees', 'are', 'vital', 'to', 'life', 'on', 'earth', 'they', 'provide', 'us', 'with', 'oxygen', 'improve', 'air', 'quality', 'conserve', 'water', 'and', 'support', 'countless', 'ecosystems', 'trees', 'offer', 'shade', 'reduce', 'the', 'effects', 'of', 'climate', 'change', 'by', 'absorbing', 'carbon', 'dioxide', 'and', 'prevent', 'soil', 'erosion', 'with', 'their', 'strong', 'roots', 'they', 'also', 'provide', 'food', 'shelter', 'and', 'protection', 'for', 'many', 'species', 'of', 'animals', 'in', 'urban', 'areas', 'trees', 'enhance', 'beauty', 'lower', 'temperatures', 'and', 'promote', 'wellbeing', 'among', 'people', 'forests', 'made', 'up', 'of', 'trees', 'are', 'often', 'called', 'the', 'lungs', 'of', 'our', 'planet', 'without', 'trees', 'life', 'as', 'we', 'know', 'it', 'would', 'not', 'be', 'possible', 'protecting', 'and', 'planting', 'trees', 'is', 'crucial', 'for', 'our', 'future'] \n",
      "\n",
      "Only alpha words:\n",
      " ['trees', 'are', 'vital', 'to', 'life', 'on', 'earth', 'they', 'provide', 'us', 'with', 'oxygen', 'improve', 'air', 'quality', 'conserve', 'water', 'and', 'support', 'countless', 'ecosystems', 'trees', 'offer', 'shade', 'reduce', 'the', 'effects', 'of', 'climate', 'change', 'by', 'absorbing', 'carbon', 'dioxide', 'and', 'prevent', 'soil', 'erosion', 'with', 'their', 'strong', 'roots', 'they', 'also', 'provide', 'food', 'shelter', 'and', 'protection', 'for', 'many', 'species', 'of', 'animals', 'in', 'urban', 'areas', 'trees', 'enhance', 'beauty', 'lower', 'temperatures', 'and', 'promote', 'wellbeing', 'among', 'people', 'forests', 'made', 'up', 'of', 'trees', 'are', 'often', 'called', 'the', 'lungs', 'of', 'our', 'planet', 'without', 'trees', 'life', 'as', 'we', 'know', 'it', 'would', 'not', 'be', 'possible', 'protecting', 'and', 'planting', 'trees', 'is', 'crucial', 'for', 'our', 'future']\n",
      "\n",
      "Words starting with vowels:\n",
      " ['are', 'on', 'earth', 'us', 'oxygen', 'improve', 'air', 'and', 'ecosystems', 'offer', 'effects', 'of', 'absorbing', 'and', 'erosion', 'also', 'and', 'of', 'animals', 'in', 'urban', 'areas', 'enhance', 'and', 'among', 'up', 'of', 'are', 'often', 'of', 'our', 'as', 'it', 'and', 'is', 'our']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "letter_5 = re.findall(r'\\b\\w{6,}\\b', no_punc)\n",
    "print(\"words (>5) letters:  \", letter_5 ,'\\n')\n",
    "\n",
    "numb = re.findall(r'\\b\\d+\\b', no_punc)\n",
    "print(\"\\nNumbers :  \", numb,'\\n')\n",
    "\n",
    "caps = re.findall(r'\\b[A-Z][a-zA-Z]*\\b', sentence)\n",
    "print(\"\\nCapitalized :  \", caps, '\\n')\n",
    "\n",
    "alphas = re.findall(r'\\b[a-zA-Z]+\\b', no_punc)\n",
    "print(\"\\nOnly alpha words:  \", alphas, '\\n')\n",
    "\n",
    "words_list = no_punc.split()\n",
    "only_alpha_words = [w for w in words_list if w.isalpha()]\n",
    "print(\"Only alpha words:\\n\", only_alpha_words)\n",
    "\n",
    "vowelss = [w for w in alphas if w[0].lower() in 'aeiou']\n",
    "print(\"\\nWords starting with vowels:\\n\", vowelss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a84f3-f396-475f-ab62-cdf9f3ea6ed7",
   "metadata": {},
   "source": [
    "# Q4. Custom Tokenization & Regex-based Text Cleaning\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Input**: Use the original text from **Question 1**.\n",
    "\n",
    "2. **Custom Tokenization Function Requirements**:\n",
    "   \n",
    "   - **(a)** Remove punctuation and special symbols, **but keep contractions** (e.g., `\"isn't\"` should remain `\"isn't\"` and not split into `\"is\"` and `\"n't\"`).\n",
    "   \n",
    "   - **(b)** Handle **hyphenated words** as **single tokens** (e.g., `\"state-of-the-art\"` should remain as one token).\n",
    "   \n",
    "   - **(c)** **Tokenize numbers separately**, but **keep decimal numbers intact** (e.g., `\"3.14\"` should remain `\"3.14\"`).\n",
    "\n",
    "3. **Regex Substitutions** (using `re.sub`):\n",
    "\n",
    "   - **(a)** Replace **email addresses** with the placeholder `<EMAIL>`.\n",
    "   \n",
    "   - **(b)** Replace **URLs** with the placeholder `<URL>`.\n",
    "   \n",
    "   - **(c)** Replace **phone numbers** (formats like `123-456-7890` or `+91 9876543210`) with the plceho-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\n",
    "placeholder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ba0f752-0f2b-4d70-b76d-b5b16fd6cc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Tokens:   ['Trees', 'are', 'vital', 'to', 'life', 'on', 'Earth', 'They', 'provide', 'us', 'with', 'oxygen', 'improve', 'air', 'quality', 'conserve', 'water', 'and', 'support', 'countless', 'ecosystems', 'Trees', 'offer', 'shade', 'reduce', 'the', 'effects', 'of', 'climate', 'change', 'by', 'absorbing', 'carbon', 'dioxide', 'and', 'prevent', 'soil', 'erosion', 'with', 'their', 'strong', 'roots', 'They', 'also', 'provide', 'food', 'shelter', 'and', 'protection', 'for', 'many', 'species', 'of', 'animals', 'In', 'urban', 'areas', 'trees', 'enhance', 'beauty', 'lower', 'temperatures', 'and', 'promote', 'well-being', 'among', 'people', 'Forests', 'made', 'up', 'of', 'trees', 'are', 'often', 'called', 'the', 'lungs', 'of', 'our', 'planet', 'Without', 'trees', 'life', 'as', 'we', 'know', 'it', 'would', 'not', 'be', 'possible', 'Protecting', 'and', 'planting', 'trees', 'is', 'crucial', 'for', 'our', 'future'] \n",
      "\n",
      "\n",
      "Text after Regex Substitutions:\n",
      " \n",
      "Trees are vital to life on Earth. They provide us with oxygen, improve air quality, conserve water, and support countless ecosystems. Trees offer shade, reduce the effects of climate change by absorbing carbon dioxide, and prevent soil erosion with their strong roots. They also provide food, shelter, and protection for many species of animals. In urban areas, trees enhance beauty, lower temperatures, and promote well-being among people. Forests, made up of trees, are often called the lungs of our planet. Without trees, life as we know it would not be possible. Protecting and planting trees is crucial for our future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def custom_tokens(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s\\-']\", \"\", text)\n",
    "    tokens = re.findall(r\"\\b\\w+(?:[-']\\w+)*\\b\", text)\n",
    "    return tokens\n",
    "customs = custom_tokens(sentence)\n",
    "print(\"\\nCustom Tokens:  \", customs, '\\n')\n",
    "\n",
    "\n",
    "text_replaced = re.sub(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', '<EMAIL>', sentence)\n",
    "\n",
    "text_replaced = re.sub(r'http[s]?://\\S+', '<URL>', text_replaced)\n",
    "\n",
    "text_replaced = re.sub(r'(\\+?\\d{1,2}\\s?)?(\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4})', '<PHONE>', text_replaced)\n",
    "\n",
    "print(\"\\nText after Regex Substitutions:\\n\", text_replaced)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
